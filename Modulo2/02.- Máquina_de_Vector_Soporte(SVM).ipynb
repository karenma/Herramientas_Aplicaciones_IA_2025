{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bbfa8f3",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#000047; padding: 30px; border-radius: 10px; color: white; text-align: center;\">\n",
    "    <img src='Figures/alinco.png' style=\"height: 100px; margin-bottom: 10px;\"/>\n",
    "    <h1>Máquinas de Vector Soporte (SVM)</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc4ba7",
   "metadata": {},
   "source": [
    "Generalmente, `Support Vector Machines` se considera un algoritmo de aprendizaje supervizado para clasificación, pero puede emplearse en ambos tipos de problemas de clasificación y regresión. \n",
    "\n",
    ">Puede manejar fácilmente múltiples variables continuas y categóricas.\n",
    "\n",
    ">SVM construye un hiperplano en un espacio multidimensional para separar diferentes clases.\n",
    "\n",
    ">SVM genera un hiperplano óptimo de manera iterativa, que se utiliza para minimizar un error. La idea central de SVM es encontrar un hiperplano marginal máximo (MMH) que divida mejor el conjunto de datos en clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba68033",
   "metadata": {},
   "source": [
    "> **Vectores Soportes:** Los vectores de soporte son los puntos de datos más cercanos al hiperplano. Estos puntos definirán mejor la línea de separación calculando los márgenes. Estos puntos son más relevantes para la construcción del clasificador.\n",
    "\n",
    "> **Hiperplano:** Un hiperplano es un plano de decisión que separa un conjunto de objetos que tienen diferentes membresías de clase.\n",
    "\n",
    ">**Margen:** Un margen es un espacio que existe entre dos líneas obtenidas en función de los puntos de cada clase. Esto se calcula como la distancia perpendicular desde la línea hasta los vectores soporte o los puntos más cercanos. Si el margen es mayor entre las clases, entonces se considera un buen margen, un margen más pequeño es un mal margen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b1760",
   "metadata": {},
   "source": [
    "### Algoritmo\n",
    "El objetivo principal es segregar el conjunto de datos dado de la mejor manera posible. La distancia entre los puntos más cercanos se conoce como margen. El objetivo es seleccionar un hiperplano con el máximo margen posible entre los vectores de soporte en el conjunto de datos dado. SVM busca el hiperplano marginal máximo.\n",
    "\n",
    "\n",
    "1. Basada en kernels que realiza clasificación lineal sobre vectores transformados a un espacio de dimensión superior, es decir, separa mediante un hiperplano en el espacio transformado.\n",
    "\n",
    "2. Encuentra el hiperplano que maximiza el “margen” entre dos clases\n",
    "\n",
    "\n",
    "Un hiperplano en un espacio n-dimensional se define como:\n",
    "\n",
    "$$ \\mathbf{w}^T \\mathbf{x} + b = 0 $$\n",
    "\n",
    "Donde:\n",
    "- $\\mathbf{w}$: vector de pesos\n",
    "- $\\mathbf{x}$: vector de características\n",
    "- $b$: sesgo (bias)\n",
    "\n",
    "SVM busca maximizar la distancia (margen) entre el hiperplano y los puntos más cercanos de cada clase.\n",
    "\n",
    "La optimización se expresa como:\n",
    "\n",
    "$$ \\min_{\\mathbf{w}, b} \\frac{1}{2} ||\\mathbf{w}||^2 $$\n",
    "\n",
    "Sujeto a:\n",
    "\n",
    "$$ y_i (\\mathbf{w}^T \\mathbf{x}_i + b) \\geq 1 $$\n",
    "\n",
    "Donde $y_i$ es la etiqueta de clase (+1 o -1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d8abf",
   "metadata": {},
   "source": [
    "**Visualmente**\n",
    "<img src='https://scikit-learn.org/stable/_images/sphx_glr_plot_separating_hyperplane_001.png' width='600' style='border-radius:8px;'/>\n",
    "\n",
    "En la imagen, el hiperplano separa dos clases y los vectores de soporte son los puntos más cercanos al margen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf73e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples = 50, centers = 2, random_state=0, cluster_std=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0640e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(-1,3.5)\n",
    "plt.scatter(X[:,0],X[:,1],c=y,s=50,cmap='jet')\n",
    "\n",
    "plt.plot([0.6],[2.1], 'x',color='red',\n",
    "        markeredgewidth=2,markersize=10)\n",
    "\n",
    "for m, b in [(1,0.65),(0.5,1.6),(-0.2,2.9)]:\n",
    "    plt.plot(xfit,m*xfit + b, '-k')\n",
    "\n",
    "plt.xlim(-1,3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8814bf7",
   "metadata": {},
   "source": [
    "La intuicion de SVM es que podemos dibujar una recta para clasificar las clases y dibijuar un margén de cierta distancia entre las rectas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(-1,3.5)\n",
    "plt.scatter(X[:,0],X[:,1],c=y,s=50,cmap='jet')\n",
    "\n",
    "\n",
    "for m, b,d in [(1,0.65,0.33),(0.5,1.6,0.55),(-0.2,2.9,0.2)]:\n",
    "    yfit = m*xfit + b\n",
    "    plt.plot(xfit,yfit, '-k')\n",
    "    plt.fill_between(xfit,yfit - d, yfit +d, \n",
    "                     edgecolor='none',\n",
    "                    color = '#AAAAAA',alpha=0.4)\n",
    "plt.xlim(-1,3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880fb52",
   "metadata": {},
   "source": [
    "La linea que maximiza ese margen es la que se escoge como el modelo óptimo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd3cdd",
   "metadata": {},
   "source": [
    "### Ejemplo 1: Datos Linealmente separables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83652649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693b6117",
   "metadata": {},
   "source": [
    "### Definición de la clase SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f8de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregar a su librería\n",
    "class SVM:\n",
    "    def __init__(self, lr=0.001, lambda_param=0.01, n_iters=1000):\n",
    "        self.lr = lr  #Tasa de aprendizaje utilizada para actualizar los parámetros durante la optimización.\n",
    "        self.lambda_param = lambda_param  #Parámetro de regularización que controla la penalización sobre los pesos para evitar sobreajuste.\n",
    "        self.n_iters = n_iters  #Número de iteraciones (épocas) para el proceso de entrenamiento.\n",
    "        self.w = None  #Vector de pesos del hiperplano que separa las clases.\n",
    "        self.b = None  #Término de sesgo (bias) que ajusta la posición del hiperplano.\n",
    "\n",
    "    def fit(self, X, y):\n",
    "       \n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d7e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from HyAIA import HyAIA as hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f952704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = hy.train_test_split(pd.DataFrame(X), \n",
    "                                                                   pd.DataFrame(y), test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provar la clase SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fc0f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecir el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870de407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# método para probar el accuracy del modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca66470d",
   "metadata": {},
   "source": [
    "### Modelo con librería sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440ec5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import(accuracy_score, \n",
    "                            precision_score,\n",
    "                            recall_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9203d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear el modelo con SVM\n",
    "\n",
    "#Entrenar al modelo\n",
    "\n",
    "# Predecir (evaluar al modelo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1488b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicción para el testeo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392869a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujar el hiperplano de separación\n",
    "beta = modelo_svm.coef_[0]\n",
    "m = -beta[0]/beta[1]\n",
    "\n",
    "xx = np.linspace(-1,4)\n",
    "yy = m*xx - (modelo_svm.intercept_[0]/beta[1])\n",
    "\n",
    "vs = modelo_svm.support_vectors_\n",
    "\n",
    "#%% Margenes de separación\n",
    "b = vs[0]\n",
    "yy_down = m*xx + (b[1] - m*b[0])\n",
    "\n",
    "b = vs[-1]\n",
    "yy_up = m*xx + (b[1] - m*b[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb3592",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(X[:,0], X[:,1], c=y)\n",
    "plt.plot(xx,yy_up,'k--')\n",
    "plt.plot(xx,yy_down,'k--')\n",
    "plt.scatter(vs[:,0], vs[:,1], s=80, facecolor='k')\n",
    "plt.plot(xx,yy)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d79565",
   "metadata": {},
   "source": [
    "### Tratar con datos que no son linealmente separables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947ae4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar los datos \n",
    "data = pd.read_csv('Data/ex2data2.txt', header=None)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2da0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = data.iloc[:,:-1]\n",
    "y_df = data.iloc[:,-1]\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = hy.train_test_split(pd.DataFrame(X_df), \n",
    "                                                                   pd.DataFrame(y_df), test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eeaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.shape, y_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f636d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df.shape,y_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(data.iloc[:,0], data.iloc[:,1], c = data.iloc[:,2])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604e9e5e",
   "metadata": {},
   "source": [
    "Algunos problemas no se pueden resolver utilizando un hiperplano lineal.\n",
    "\n",
    ">En tal situación, **SVM** usa un truco del kernel para transformar el espacio de entrada en un espacio dimensional más grande. \n",
    "\n",
    "**SVM Kernels**\n",
    "\n",
    "El algoritmo SVM se implementa en la práctica utilizando un kernel. \n",
    "\n",
    ">Un **kernel** transforma un espacio de datos de entrada en la forma requerida. Aquí, el kernel toma un espacio de entrada de menor dimensión y lo transforma en un espacio de mayor dimensión. En otras palabras, se puede decir que se convierte un problema no linealmente separable en problemas separables al agregarle una mayor dimensión. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df74b5f3",
   "metadata": {},
   "source": [
    "\n",
    "<img alt=\"Datos categóricos con Python\" title=\"Datos categóricos con Python\" src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTJKujfCumij1R0vDYuPFSbys3-Du7hrrIwTBHO4J06Ivi6MkFIJa7NQnE1rITiNoLaUro&usqp=CAU\" high=200px width=300px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b3109",
   "metadata": {},
   "source": [
    "**Kernel lineal** Se puede utilizar un kernel lineal como producto escalar normal cualesquiera dos observaciones dadas. El producto entre dos vectores es la suma de la multiplicación de cada par de valores de entrada.\n",
    "\n",
    "$$K(x,x_i) = \\sum(x*x_i) $$\n",
    "\n",
    "\n",
    "**Kernel polinomial** Un kernel polinomial es una forma más generalizada del kernel lineal. El kernel polinomial puede distinguir el espacio de entrada curvo o no lineal.\n",
    "\n",
    "$$K(x,x_i) = 1 \\sum(x*x_i)^d $$\n",
    "\n",
    "Donde $d$ es el grado del polinomio. $d = 1$ es similar a la transformación lineal. \n",
    "\n",
    "**Kernel de función de base radial (RBF)** RBF puede mapear un espacio de entrada en un espacio dimensional infinito.\n",
    "\n",
    "$$K(x,x_i) = exp(-\\gamma * \\sum(x – x_i^2))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e2010d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(svm.SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a69a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Crear y entrenar el modelo SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1887e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo polinomial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edcb14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo polinomial grado 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12881d87",
   "metadata": {},
   "source": [
    "### Practica:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f854ac36",
   "metadata": {},
   "source": [
    "Considere el dataset \"apples_and_oranges.csv\" que se encuentra en la carpeta de Data, realize una clasificación por SVM utilizando los diferentes kernels: linear, poly, rbf. Grafique los datos con su clasificación y los vectores soportes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e3aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/apples_and_oranges.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d550f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db4e16-2fff-43ae-9c96-59995554f25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254c426-8b8d-44e1-8972-756cdbc88272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
